{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pylegoclassifier workbook\n",
    "### magnus wood, december 2020, bsyse 530 semester project\n",
    "The below code block will be used in the 'pylegoclassifer.py' module. It will be used in the matlab integration, where images obtained by Eric will use functions from this code to do lego color classification.\n",
    "\n",
    "This jupyter notebook exists solely for developing it. I should probably share it too.\n",
    "\n",
    "### pylegoclassifier.py functionality\n",
    "### The code needs to do this:\n",
    "\n",
    "1. Take an image file in and ensure it is in the right format.\n",
    "2. Perform background segmentation using ImageSegmentation.\n",
    "3. Data extraction:\n",
    "    a. \n",
    "    b. \n",
    "4. Pass the dataframe to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pylegoclassifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pylegoclassifier.py\n",
    "\n",
    "# import the needed packages\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import randint, uniform\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "import os\n",
    "from math import pi\n",
    "from math import isnan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from skimage.filters import sobel\n",
    "\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(26)\n",
    "\n",
    "# the NaiveBayes classifier I wrote for assignment 6 in BSYSE_530, modified a little for this purpose\n",
    "class NaiveBayes:\n",
    "    # P(c|x) = P(x|c) * P(c) / P(x)\n",
    "    # P(x|x) is the posterior probability\n",
    "    # P(x|c) is the likelihood\n",
    "    # P(c) is the class prior probability, or the prob of c occuring indpendently. \n",
    "    # P(x) is the predictor prior probability, or the prob of x occuring independently\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        # define class variables\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        # calculate statistics for all those features\n",
    "        self.calc_statistics(features, target)\n",
    "        \n",
    "        # prior is the random chance of drawing a particular class based on its proportion in the dataset\n",
    "        self.prior = self.calc_prior(features, target)\n",
    "        \n",
    "              \n",
    "    def get_predictions(self, input_vector):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(len(input_vector)):\n",
    "            result = self.calc_posterior((input_vector.iloc[i,:]))\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "     \n",
    "\n",
    "    def predict(self, observation):\n",
    "        #call the calc_posterior function on the observation\n",
    "        pred_class = self.calc_posterior(observation)\n",
    "        return pred_class\n",
    "        \n",
    "        \n",
    "    def calc_statistics(self, features, target):\n",
    "        # calculate mean, variance for each column and convert to numpy array\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    \n",
    "    def calc_prior(self, features, target):\n",
    "        # this is the probability of picking one of a class at random from the dataset\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)/self.rows).to_numpy())\n",
    "        return self.prior\n",
    "    \n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        # this is the probability, post evidence\n",
    "        # x is a numpy array\n",
    "        # x is feature vector for one observation \n",
    "                \n",
    "        # make a list that we will add each classes posterior prob to\n",
    "        posteriors = []\n",
    "        \n",
    "        # iterate through the classes\n",
    "        for i in range(0, self.count):\n",
    "            # for each class look at the prior probability for the class\n",
    "            prior = self.prior[i]\n",
    "            \n",
    "            # calculate the conditional probability for the \n",
    "            conditional = np.sum(self.gaussian_density(i, x))\n",
    "            posterior = prior + conditional\n",
    "            #  print(f\"i = {i}, prior = {prior}, conditional = {conditional}, posterior = {posterior}\")\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "        \n",
    "        \n",
    "    def gaussian_density(self, class_idx, x):\n",
    "        # calc probability from gaussian denssityy fucntion (normal dist)\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        # this part sucked and I had a typo that cost me hours\n",
    "        numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "        \n",
    "    \n",
    "    def pdf(self, x, mean, stdev):\n",
    "        # calculate probability density function\n",
    "        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))\n",
    "        return exponent * (1/(np.sqrt(2*np.pi)*stdev))\n",
    "\n",
    "        \n",
    "    def get_accuracy(self, test, predictions):\n",
    "        correct = 0\n",
    "        for i in range(len(test)):\n",
    "            if test.iloc[i] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct / float(len(test)))\n",
    "    \n",
    "\n",
    "\n",
    "# TODO: read these and see how it works        \n",
    "# https://www.mathworks.com/help/matlab/matlab_external/matlab-arrays-as-python-variables.html        \n",
    "# https://www.mathworks.com/help/matlab/matlab_external/passing-data-to-python.html        \n",
    "            \n",
    "# this exists only for my testing purposes\n",
    "class MatlabSurrogate():\n",
    "    def __init__(self):\n",
    "        self.state_of_mind = \"Badass.\"\n",
    "        \n",
    "        \n",
    "    def acquire_kinect_image(self, filename):\n",
    "        # give this function a filename, and it will load that image with opencv\n",
    "        # this will be a BGR format, because that is how opencv rolls\n",
    "        kinect_image = cv.imread(filename)\n",
    "        print(f\"kinect has acquired the image with shape = {kinect_image.shape}\")\n",
    "        return kinect_image\n",
    "    \n",
    "    \n",
    "    # function to display images resized, using opencv\n",
    "    def imshow(self, image, imdiv = 4):\n",
    "        imdiv = int(imdiv)\n",
    "        w, h = int(image.shape[1]/imdiv), int(image.shape[0]/imdiv)\n",
    "        cv.namedWindow(\"output\", cv.WINDOW_NORMAL)\n",
    "        cv.resizeWindow(\"output\", (w, h))\n",
    "        cv.imshow(\"output\", image)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "# I should probably have one image processing class that takes in a single image and then spits out a dataframe that could be used for prediction\n",
    "# replaces ImageSegmenter\n",
    "class ImageProcess():\n",
    "    def __init__(self):\n",
    "        print(\"image processor activated! use 'process_image_to_df()' to get back a pandas df\")\n",
    "        self.black_lower = (0, 0, 0)\n",
    "        self.black_upper = (179, 255, 30)\n",
    "        self.hsv_lower = (0, 0, 0)\n",
    "        self.hsv_upper = (179, 255, 90)\n",
    "#         self.black_lower = (0, 0, 203)\n",
    "#         self.black_upper = (43, 255, 255)\n",
    "#         self.hsv_lower = (0, 0, 70)\n",
    "#         self.hsv_upper = (179, 34, 255)\n",
    "# NOT mask for lego_imgs[14]\n",
    "# hsv_lower = (0,0,0)\n",
    "# hsv_upper = (179,234,77)\n",
    "\n",
    "    \n",
    "\n",
    "    def dummy_method(self, a):\n",
    "        if type(a) is np.ndarray:\n",
    "            result = \"object is a numpy.ndarray, this is perfect. Is the image RGB order or BGR?\"\n",
    "            return result\n",
    "        else:\n",
    "            result = \"object is a \" + str(type(a)) + \"and I'm gonna have a hard time with that\"\n",
    "            return result\n",
    "      \n",
    "    \n",
    "        \n",
    "    def bg_segmentation(self, image, mode=\"hsv\", show_img=False):\n",
    "                \n",
    "            # create an hsv mask for red colors\n",
    "            hsv_mask = cv.inRange(cv.cvtColor(image, cv.COLOR_BGR2HSV), \n",
    "                                 self.hsv_lower,\n",
    "                                 self.hsv_upper).astype(np.uint8)\n",
    "             \n",
    "            # use this as a NOT mask\n",
    "            hsv_mask = np.where(hsv_mask > 1, 0, 1).astype(np.uint8)\n",
    "  \n",
    "            hsv_mask = ndimage.gaussian_filter(hsv_mask, sigma=1)\n",
    "\n",
    "            # erode the mask\n",
    "            hsv_mask = morphology.erosion(hsv_mask, morphology.disk(3))\n",
    "\n",
    "#             # median filter to despeckle\n",
    "#             hsv_mask = ndimage.median_filter(hsv_mask, size=(3, 3)).astype(np.uint8)\n",
    "\n",
    "            # binary dilation \n",
    "            hsv_mask = morphology.binary_dilation(hsv_mask, np.ones((20, 20))).astype(np.uint8)\n",
    "\n",
    "            # fill the holes\n",
    "            hsv_mask = ndimage.binary_fill_holes(hsv_mask).astype(np.uint8)\n",
    "\n",
    "            # erode the mask\n",
    "            hsv_mask = morphology.erosion(hsv_mask, morphology.disk(5))\n",
    "            \n",
    "            # TODO: remove this it is for testing purposes to show the segmentation\n",
    "            if (show_img == True):                \n",
    "                m = MatlabSurrogate()\n",
    "                m.imshow(cv.bitwise_and(image, image, mask=hsv_mask).astype(np.uint8))\n",
    "            \n",
    "            # apply the mask and return the result        \n",
    "            return cv.bitwise_and(image, image, mask=hsv_mask).astype(np.uint8)\n",
    "\n",
    "\n",
    "    \n",
    "    def process_image_to_df(self, input_image, area_th):\n",
    "        \n",
    "        seg_img = self.bg_segmentation(input_image, show_img=False)\n",
    "\n",
    "    #     # make the mask a binary thresholded image\n",
    "        mask = cv.cvtColor(seg_img, cv.COLOR_BGR2GRAY)\n",
    "        mask = cv.GaussianBlur(mask,(5,5),0)\n",
    "        ret3, mask = cv.threshold(mask,0,255,cv.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "        # output image with contours drawn on the original image\n",
    "        output_image = input_image.copy()\n",
    "\n",
    "        # find the contours of the detected objects in the image\n",
    "        contours, hier = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        # create the df that we'll return for this image\n",
    "        df = pd.DataFrame(columns=['color'])\n",
    "\n",
    "        # # reset the object num\n",
    "        object_num = 0\n",
    "        \n",
    "        for cnt in contours:\n",
    "            # draw contours on the output image for our personal enjoyment\n",
    "            cv.drawContours(output_image, [cnt], 0, color=(255, 255, 255), thickness=5)\n",
    "            # CALCULATE ALL THE CONTOUR SHAPE FEATURES\n",
    "\n",
    "            # get the x, y, w, h of the bounding rect for the contour\n",
    "            x, y, w, h = cv.boundingRect(cnt)\n",
    "\n",
    "            # contour features\n",
    "            area = cv.contourArea(cnt)\n",
    "            rect_area = w * h\n",
    "            fullosity = area / rect_area\n",
    "\n",
    "            aspect_ratio = float(w)/h\n",
    "            extent = float(area/ rect_area)\n",
    "            hull = cv.convexHull(cnt)\n",
    "            hull_area = cv.contourArea(hull)\n",
    "            solidity = float(area)/hull_area\n",
    "\n",
    "            eq_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            M= cv.moments(cnt)\n",
    "            cx= int(M['m10']/M['m00'])\n",
    "            cy= int(M['m01']/M['m00'])\n",
    "\n",
    "            # take this rectangle as a subset of the input_image, and calculate things within it\n",
    "            img_subset = input_image[y:y+h, x:x+w, :]\n",
    "\n",
    "            # convert to hsv for extracting those values\n",
    "            img_subset_hsv = cv.cvtColor(img_subset, cv.COLOR_BGR2HSV)\n",
    "\n",
    "            # FILTER OUT THE WEIRD ONES\n",
    "            # get rid of tiny objects that are probably noisef\n",
    "            if area > area_th:\n",
    "                # draw a blank canvas to put the contour onto, JUST THIS ONE not the others\n",
    "                # this is a mask\n",
    "                cimg_justthiscontour = np.zeros_like(input_image)\n",
    "\n",
    "                # draw the contours on the blank canvas which is original sized\n",
    "                cv.drawContours(cimg_justthiscontour, [cnt], 0, color=(255, 255, 255), thickness=-1)\n",
    "\n",
    "                # now take the subset of just the area around the contour of interest\n",
    "                cimg_subset = cimg_justthiscontour[y:y+h, x:x+w, :]\n",
    "\n",
    "                # make a binary mask\n",
    "                cimg_mask = cv.cvtColor(cimg_subset, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "                ret2, mask = cv.threshold(cimg_mask,0,255,cv.THRESH_BINARY)\n",
    "\n",
    "                # draw contours on the output image for our personal enjoyment\n",
    "                cv.drawContours(output_image, [cnt], 0, color=(255, 255, 255), thickness=5)\n",
    "\n",
    "                img_subset = cv.bitwise_and(img_subset, img_subset, mask=mask).astype(np.uint8)\n",
    "\n",
    "                # calculate where the object is\n",
    "                pts = np.where(cimg_subset == 255)\n",
    "                hue = img_subset_hsv[pts[0], pts[1], 0]\n",
    "                sat = img_subset_hsv[pts[0], pts[1], 1]\n",
    "                val = img_subset_hsv[pts[0], pts[1], 2]\n",
    "                r = img_subset[pts[0], pts[1], 0]\n",
    "                g = img_subset[pts[0], pts[1], 1]\n",
    "                b = img_subset[pts[0], pts[1], 2]\n",
    "\n",
    "                # and export the image for later analysis with something else like a neural network\n",
    "                cv.imwrite(f\"images/train/XX_{object_num}_{randint(10000,99999)}.png\", img_subset)\n",
    "\n",
    "                # add the object labels to the cimg for identification\n",
    "                cv.putText(output_image, text= str(object_num), \n",
    "                           org=(cx - 5,cy - 5), \n",
    "                           fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "                           fontScale=3, \n",
    "                           color=(255,255,255), \n",
    "                           thickness=5, \n",
    "                           lineType=cv.LINE_AA)\n",
    "\n",
    "        #         print(r.mean(), g.mean(), b.mean(), gli.mean())\n",
    "                df = df.append({'color' : 0,\n",
    "                                'x': x,\n",
    "                                'y': y,\n",
    "                                'object_num': object_num,\n",
    "                                'r': r.mean(),\n",
    "                                'g': g.mean(),\n",
    "                                'b': b.mean(),\n",
    "                                'hue': hue.mean(),\n",
    "                                'sat': sat.mean(),\n",
    "                                'val': val.mean()\n",
    "                                 }, ignore_index=True)\n",
    "\n",
    "                # last thing we do on this loop is increment the object_num\n",
    "                object_num += 1\n",
    "\n",
    "            #\n",
    "\n",
    "        # end result should be a pandas dataframe and the contour image with numbers\n",
    "        return df.sort_values(by='object_num', axis=0, ascending=True), output_image\n",
    "    \n",
    "    def hsv_slide_tool(self, image):\n",
    "        \n",
    "        def empty(a):\n",
    "            pass\n",
    "        \n",
    "        h, w = int(image.shape[1]/2), int(image.shape[0]/2)\n",
    "        cv.namedWindow('masked_image', cv.WINDOW_NORMAL)\n",
    "        cv.resizeWindow('masked_image', h, w)\n",
    "        \n",
    "        cv.namedWindow(\"trackbars\")\n",
    "        cv.resizeWindow(\"trackbars\", 800, 300)\n",
    "                \n",
    "        # color mask trackbars\n",
    "        cv.createTrackbar(\"hue_min\", \"trackbars\", 0, 179, empty)\n",
    "        cv.createTrackbar('hue_max', 'trackbars', 179, 179, empty)\n",
    "        cv.createTrackbar('sat_min', 'trackbars', 0, 255, empty)\n",
    "        cv.createTrackbar('sat_max', 'trackbars', 255, 255, empty)\n",
    "        cv.createTrackbar('val_min', 'trackbars', 0, 255, empty)\n",
    "        cv.createTrackbar('val_max', 'trackbars', 255, 255, empty)\n",
    "       \n",
    "\n",
    "        while True:\n",
    "            # get image\n",
    "            img_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "            \n",
    "            # get trackbar positions\n",
    "            h_min = cv.getTrackbarPos(\"hue_min\", \"trackbars\")\n",
    "            h_max = cv.getTrackbarPos('hue_max', 'trackbars')\n",
    "            s_min = cv.getTrackbarPos('sat_min', 'trackbars')\n",
    "            s_max = cv.getTrackbarPos('sat_max', 'trackbars')\n",
    "            v_min = cv.getTrackbarPos('val_min', 'trackbars')\n",
    "            v_max = cv.getTrackbarPos('val_max', 'trackbars')\n",
    "            \n",
    "            #         self.black_lower = (0, 0, 0)\n",
    "#         self.black_upper = (179, 255, 30)\n",
    "#         self.hsv_lower = (0, 0, 100)\n",
    "#         self.hsv_upper = (179, 255, 255)\n",
    "            \n",
    "            # create mask\n",
    "            hsv_lower = np.array([h_min, s_min, v_min])\n",
    "            hsv_upper = np.array([h_max, s_max, v_max])\n",
    "            black_lower = np.array([0, 0, 0])\n",
    "            black_upper = np.array([179, 255, 30])\n",
    "            \n",
    "            color_mask = cv.inRange(img_hsv, hsv_lower, hsv_upper)\n",
    "            black_mask = cv.inRange(img_hsv, black_lower, black_upper)\n",
    "            mask = color_mask + black_mask\n",
    "            masked_image = cv.bitwise_and(img_hsv, img_hsv, mask=mask)\n",
    "            \n",
    "            cv.imshow('masked_image', masked_image)\n",
    "            k = cv.waitKey(1000) & 0xFF # large wait time\n",
    "            if k == 113 or k == 27:\n",
    "                break\n",
    "        \n",
    "        cv.destroyAllWindows()\n",
    "        print(f'hsv_lower is {hsv_lower}, hsv_upper = {hsv_upper}')\n",
    "              \n",
    " \n",
    "        \n",
    "    def label_dataframe(self, image_df, class_list):\n",
    "        for i, row in image_df.iterrows():\n",
    "            image_df.loc[i, 'color'] = class_list[i]\n",
    "        print(type(image_df))\n",
    "        return image_df\n",
    "    \n",
    "#     def fake_df(self, input_df, reps = 3):\n",
    "#         # creates a bunch of fake adjustments to the dataframe so my train set is bigger\n",
    "#         output_df = input_df.copy()\n",
    "        \n",
    "#         for rep in range(0, reps):\n",
    "#             fake_df = input_df.copy()\n",
    "#             for i, row in fake_df.iterrows():\n",
    "#                 fake_df.loc[i, 'r'] = fake_df.loc[i, 'r'] + uniform(-.1, .1)\n",
    "#                 fake_df.loc[i, 'g'] = fake_df.loc[i, 'g'] + uniform(-.1, .1)\n",
    "#                 fake_df.loc[i, 'b'] = fake_df.loc[i, 'b'] + uniform(-.1, .1)\n",
    "#             output_df = pd.concat(output_df, fake_df)\n",
    "                \n",
    "#         return output_df\n",
    "        \n",
    "    def otsu_threshold(self, image):\n",
    "        blur = cv.GaussianBlur(image,(5,5),0)\n",
    "        ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        return ret3, th3\n",
    "\n",
    "    def process_image_make_predictions(self, input_image, model):\n",
    "        \n",
    "        predictive_model = model\n",
    "        \n",
    "        \n",
    "        area_th = 400\n",
    "        \n",
    "        seg_img = self.bg_segmentation(input_image, show_img=False)\n",
    "\n",
    "    #     # make the mask a binary thresholded image\n",
    "        mask = cv.cvtColor(seg_img, cv.COLOR_BGR2GRAY)\n",
    "        mask = cv.GaussianBlur(mask,(5,5),0)\n",
    "        ret3, mask = cv.threshold(mask,0,255,cv.THRESH_BINARY)\n",
    "\n",
    "        # output image with contours drawn on the original image\n",
    "        output_image = input_image.copy()\n",
    "\n",
    "        # find the contours of the detected objects in the image\n",
    "        contours, hier = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # create the df that we'll return for this image\n",
    "        df = pd.DataFrame(columns=['color'])\n",
    "\n",
    "        # # reset the object num\n",
    "        object_num = 0\n",
    "        \n",
    "        for cnt in contours:\n",
    "            # draw contours on the output image for our personal enjoyment\n",
    "            cv.drawContours(output_image, [cnt], 0, color=(255, 255, 255), thickness=5)\n",
    "            # CALCULATE ALL THE CONTOUR SHAPE FEATURES\n",
    "\n",
    "            # get the x, y, w, h of the bounding rect for the contour\n",
    "            x, y, w, h = cv.boundingRect(cnt)\n",
    "\n",
    "            # contour features\n",
    "            area = cv.contourArea(cnt)\n",
    "            rect_area = w * h\n",
    "            fullosity = area / rect_area\n",
    "\n",
    "            aspect_ratio = float(w)/h\n",
    "            extent = float(area/ rect_area)\n",
    "            hull = cv.convexHull(cnt)\n",
    "            hull_area = cv.contourArea(hull)\n",
    "            solidity = float(area)/hull_area\n",
    "\n",
    "            eq_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            M= cv.moments(cnt)\n",
    "            cx= int(M['m10']/M['m00'])\n",
    "            cy= int(M['m01']/M['m00'])\n",
    "\n",
    "            # take this rectangle as a subset of the input_image, and calculate things within it\n",
    "            img_subset = input_image[y:y+h, x:x+w, :]\n",
    "\n",
    "            # convert to hsv for extracting those values\n",
    "            img_subset_hsv = cv.cvtColor(img_subset, cv.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "            # FILTER OUT THE WEIRD ONES\n",
    "            # get rid of tiny objects that are probably noisef\n",
    "            if area > area_th:\n",
    "                # draw a blank canvas to put the contour onto, JUST THIS ONE not the others\n",
    "                # this is a mask\n",
    "                cimg_justthiscontour = np.zeros_like(input_image)\n",
    "\n",
    "                # draw the contours on the blank canvas which is original sized\n",
    "                cv.drawContours(cimg_justthiscontour, [cnt], 0, color=(255, 255, 255), thickness=-1)\n",
    "\n",
    "                # now take the subset of just the area around the contour of interest\n",
    "                cimg_subset = cimg_justthiscontour[y:y+h, x:x+w, :]\n",
    "\n",
    "                # make a binary mask\n",
    "                cimg_mask = cv.cvtColor(cimg_subset, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "                ret2, mask = cv.threshold(cimg_mask,0,255,cv.THRESH_BINARY)\n",
    "\n",
    "                # draw contours on the output image for our personal enjoyment\n",
    "                cv.drawContours(output_image, [cnt], 0, color=(255, 255, 255), thickness=5)\n",
    "\n",
    "                img_subset = cv.bitwise_and(img_subset, img_subset, mask=mask).astype(np.uint8)\n",
    "\n",
    "                # calculate where the object is\n",
    "                pts = np.where(cimg_subset == 255)\n",
    "                hue = img_subset_hsv[pts[0], pts[1], 0]\n",
    "                sat = img_subset_hsv[pts[0], pts[1], 1]\n",
    "                val = img_subset_hsv[pts[0], pts[1], 2]\n",
    "                r = img_subset[pts[0], pts[1], 0]\n",
    "                g = img_subset[pts[0], pts[1], 1]\n",
    "                b = img_subset[pts[0], pts[1], 2]\n",
    "                \n",
    "                df = [{'r': (r.mean() / 255),\n",
    "                      'g': (g.mean() / 255),\n",
    "                      'b': (b.mean() / 255),\n",
    "                      'hue': (hue.mean() / 255),\n",
    "                      'sat': (sat.mean() / 255),\n",
    "                      'val': (val.mean() / 255)}]\n",
    "                \n",
    "                \n",
    "                \n",
    "                df = pd.DataFrame.from_dict(df)\n",
    "                \n",
    "                pred = predictive_model.get_predictions(df)\n",
    "                \n",
    "                class_dict = {0:\"medium_blue\",\n",
    "                              1:\"black\",\n",
    "                              2:\"darK_stone_gray\",\n",
    "                              3:\"bright_green\",\n",
    "                              4:\"light_green\",\n",
    "                              5:\"bright_orange\",\n",
    "                              6:\"bright_red\",\n",
    "                              7:\"bright_blue\",\n",
    "                              8:\"white\",\n",
    "                              9:\"bright_yellow\"}\n",
    "                color_text = class_dict[pred[0]]\n",
    "                \n",
    "                object_label = \"obj\" + str(object_num) + \"_pred\" + str(pred[0])\n",
    "                print(object_label)    \n",
    "                \n",
    "                # add the object labels to the cimg for identification\n",
    "                cv.putText(output_image, text= str(object_label), \n",
    "                           org=(cx - 5,cy - 5), \n",
    "                           fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "                           fontScale=1,\n",
    "                           color=(0,255,0), \n",
    "                           thickness=3,\n",
    "                           lineType=cv.LINE_AA)\n",
    "                \n",
    "                # last thing we do on this loop is increment the object_num\n",
    "                object_num += 1\n",
    "        \n",
    "        # AFTER ALL CONTOURS HAVE BEEN DONE submit the df to the model for predictions\n",
    "        \n",
    "#         results = predictive_model.blind_predictions()\n",
    "        # result = loaded_model.get_predictions(X_test, Y_test)\n",
    "        # print(result)\n",
    "\n",
    "        # # use the test set to see how we do\n",
    "        # y_test_predictions = nb.get_predictions(X_test)\n",
    "\n",
    "        # # scores\n",
    "        # acc = nb.get_accuracy(y_test, y_test_predictions)\n",
    "        # prec = precision_score(y_test, y_test_predictions, average=\"micro\")\n",
    "        # rec = recall_score(y_test, y_test_predictions, average=\"micro\")\n",
    "        # print(f\"precision is {prec}, recall is {rec}, accuracy = {acc}\")\n",
    "\n",
    "        # # confusion matrix\n",
    "        # labels = [(i, c) for i, c in class_dict.items()]\n",
    "        # cm = confusion_matrix(y_test, y_test_predictions)\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot(111)\n",
    "        # cax = ax.matshow(cm)\n",
    "        # plt.title('confusion matrix of the classifier')\n",
    "        # fig.colorbar(cax)\n",
    "        # plt.xlabel('Predicted')\n",
    "        # plt.ylabel('True')\n",
    "        # plt.show()\n",
    "        # print(labels)\n",
    "\n",
    "            # take the row\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        # end result should be a pandas dataframe and the contour image with numbers\n",
    "        return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab = MatlabSurrogate()\n",
    "imageproc = ImageProcess()\n",
    "\n",
    "\n",
    "# get our raw images into a list\n",
    "raw_img_path = \"images/test/\"\n",
    "lego_imgs = [(raw_img_path + f) for f in listdir(raw_img_path) if isfile(join(raw_img_path, f))]\n",
    "print(f\"there are {len(lego_imgs)} lego images in list\")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "lego_img = matlab.acquire_kinect_image(lego_imgs[idx])\n",
    "\n",
    "nb_model = pickle.load(open('nb_classifier.sav', 'rb'))\n",
    "\n",
    "result_image = imageproc.process_image_make_predictions(lego_img, nb_model)\n",
    "matlab.imshow(result_image)\n",
    "\n",
    "\n",
    "# imageproc = ImageProcess()\n",
    "\n",
    "\n",
    "# # get our raw images into a list\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# raw_img_path = \"images/raw/\"\n",
    "# lego_imgs = [(raw_img_path + f) for f in listdir(raw_img_path) if isfile(join(raw_img_path, f))]\n",
    "\n",
    "\n",
    "# idx = 0\n",
    "# # arguments to pass to the function\n",
    "# test_img1 = matlab.acquire_kinect_image(lego_imgs[idx])\n",
    "\n",
    "\n",
    "# # this will be in a function\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "        \n",
    "# df2, output_img = dummy_process(test_img1, area_th = 100)\n",
    "# matlab.imshow(output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Contructing the training data set #################\n",
    "\n",
    "\n",
    "# instantiate objects\n",
    "imageproc = ImageProcess() # does the background segmentation and other image processing methods, also data extraction\n",
    "matlab = MatlabSurrogate() # does some image loading and display, pretending we're using some \n",
    "\n",
    "# get our raw images into a list\n",
    "raw_img_path = \"images/raw/\"\n",
    "lego_imgs = [(raw_img_path + f) for f in listdir(raw_img_path) if isfile(join(raw_img_path, f))]\n",
    "print(f\"there are {len(lego_imgs)} lego images in list\")\n",
    "\n",
    "# ['images/raw/legos_0.png', \n",
    "#  'images/raw/legos_1.jpg', \n",
    "#  'images/raw/Sample1.jpg', \n",
    "#  'images/raw/Sample10.jpg', \n",
    "#  'images/raw/Sample11.jpg', \n",
    "#  'images/raw/Sample12.jpg', \n",
    "#  'images/raw/Sample13.jpg', \n",
    "#  'images/raw/Sample14.jpg', \n",
    "#  'images/raw/Sample15.jpg', \n",
    "#  'images/raw/Sample2.jpg', \n",
    "#  'images/raw/Sample3.jpg', \n",
    "#  'images/raw/Sample4.jpg', \n",
    "#  'images/raw/Sample5.jpg', \n",
    "#  'images/raw/Sample6.jpg', \n",
    "#  'images/raw/Sample7.jpg', \n",
    "#  'images/raw/Sample8.jpg', \n",
    "#  'images/raw/Sample9.jpg']\n",
    "\n",
    "# create a dummy list, we'll replace these with actual class assignments as I go\n",
    "dummy_list = [x for x in range(0, 1000)]\n",
    "\n",
    "# define the classes for each images\n",
    "# img_classes = [[0, 0, 7, 3, 4, 6, 2, 0, 2, 11, 9, 1, 10, 5],\n",
    "#               [10, 5, 1, 9, 11, 2, 8, 7]]\n",
    "img_classes = []\n",
    "\n",
    "# fill the remainded of the list that doesn't have classification already done with the dummy list\n",
    "# this is a new way to use list comprehension for me\n",
    "[img_classes.append(dummy_list) for x in range(len(lego_imgs) - len(img_classes))]\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "# f_ = pd.DataFrame(index=index, columns=columns)\n",
    "# df_ = df_.fillna(0) # with 0s rather than NaNs\n",
    "\n",
    "# class_dict = {0: \"background\",\n",
    "#               1:\"bright_yellow\",\n",
    "#               2: \"medium_blue\",\n",
    "#               3: \"darK_stone_gray\",\n",
    "#               4:\"white\",\n",
    "#               5:\"bright_red\",\n",
    "#               6:\"medium_lilac\",\n",
    "#               7:\"black\",\n",
    "#               8:\"bright_blue\",\n",
    "#               9:\"light_green\",\n",
    "#               10:\"bright_orange\",\n",
    "#               11:\"bright_green\"}\n",
    "\n",
    "# legos_0 = matlab.acquire_kinect_image(lego_imgs[0])\n",
    "# legos_1 = matlab.acquire_kinect_image(lego_imgs[1])\n",
    "\n",
    "for i, img in enumerate(lego_imgs):\n",
    "    #load\n",
    "    input_img = matlab.acquire_kinect_image(img)\n",
    "    \n",
    "    # normalize\n",
    "    lego_img = np.zeros(input_img.shape)\n",
    "    lego_img = cv.normalize(input_img,  lego_img, 0, 255, cv.NORM_MINMAX)\n",
    "    \n",
    "#     # segment\n",
    "#     seg_img = imageproc.bg_segmentation(lego_img, show_img=True)\n",
    "    \n",
    "    # load class list\n",
    "    lego_img_cl = img_classes[i]\n",
    "    \n",
    "    # process image to datagrame\n",
    "    # takes a segmented image and draws contours\n",
    "    image_df, output_img = imageproc.process_image_to_df(lego_img, area_th = 100)\n",
    "    \n",
    "    # label dataframe from class list\n",
    "    image_df = imageproc.label_dataframe(image_df, class_list = lego_img_cl)\n",
    "\n",
    "    # get image name from original filename\n",
    "    image_name = lego_imgs[i].split('/')[2].split('.')[0]\n",
    "\n",
    "    # write output_image to disk with color codes\n",
    "    cv.imwrite(f\"images/classification_{i}_{image_name}.png\", output_img)\n",
    "    \n",
    "    # add the dataframe to the training dataframe\n",
    "    if i==0:\n",
    "        train_df = image_df\n",
    "    else:\n",
    "        train_df = pd.concat([train_df, image_df])\n",
    "\n",
    "# save the training dataframe to disk\n",
    "train_df.to_csv(\"trainingdata.csv\")\n",
    "\n",
    "\n",
    "# class_dict = {0: \"background\",\n",
    "#               1:\"bright_yellow\",\n",
    "#               2: \"medium_blue\",\n",
    "#               3: \"darK_stone_gray\",\n",
    "#               4:\"white\",\n",
    "#               5:\"bright_red\",\n",
    "#               6:\"medium_lilac\",\n",
    "#               7:\"black\",\n",
    "#               8:\"bright_blue\",\n",
    "#               9:\"light_green\",\n",
    "#               10:\"bright_orange\",\n",
    "#               11:\"bright_green\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# idx = 12\n",
    "# lego_img = matlab.acquire_kinect_image(lego_imgs[idx])\n",
    "# print(lego_imgs[idx])\n",
    "# # imageproc.hsv_slide_tool(lego_img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # img = cv.cvtColor(lego_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# # global thresholding\n",
    "# ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# # Otsu's thresholding\n",
    "# ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# # Otsu's thresholding after Gaussian filtering\n",
    "# blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "# ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# # plot all the images and their histograms\n",
    "# images = [img, 0, th1,\n",
    "#           img, 0, th2,\n",
    "#           blur, 0, th3]\n",
    "# titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "#           'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "#           'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"]=20,20\n",
    "\n",
    "# for i in range(3):\n",
    "#     plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "#     plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "#     plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "#     plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the labeled dataset and scale it\n",
    "df = pd.read_csv(\"trainingdata_labeled.csv\")\n",
    "color_classes = np.unique(df['color_letter'])\n",
    "\n",
    "for i, color_letter in enumerate(color_classes):\n",
    "    print(i, color_letter)\n",
    "    df.loc[df['color_letter'] == color_letter, 'color'] = i\n",
    "\n",
    "dataset = df.drop(['color_letter', 'x', 'y', 'object_num'], axis=1)\n",
    "\n",
    "class_dict = {0:\"medium_blue\",\n",
    "              1:\"black\",\n",
    "              2:\"darK_stone_gray\",\n",
    "              3:\"bright_green\",\n",
    "              4:\"light_green\",\n",
    "              5:\"bright_orange\",\n",
    "              6:\"bright_red\",\n",
    "              7:\"bright_blue\",\n",
    "              8:\"white\",\n",
    "              9:\"bright_yellow\"}\n",
    "\n",
    "# data and labels\n",
    "y = dataset['color']\n",
    "X = dataset.drop(['color'], axis=1)\n",
    "X = X / 255\n",
    "print(X)\n",
    "\n",
    "# scalerX = preprocessing.StandardScaler().fit(X.iloc[:,1:])\n",
    "# X_scaled = scalerX.fit_transform(X.iloc[:,1:])\n",
    "\n",
    "\n",
    "print(np.unique(y))\n",
    "\n",
    "\n",
    "# # split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80)\n",
    "\n",
    "print(f'the type for X_train is {type(X_train)}, the type for X is {type(X)}')\n",
    "# # initialize the Naive Bayes class as an object\n",
    "nb = NaiveBayes()\n",
    "\n",
    "# # sumnmarize the dataset to train the model\n",
    "# # this gets class means, var, priors, etc\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# # # # make predictions using the train set\n",
    "y_train_predictions = nb.get_predictions(X_train)\n",
    "acc = nb.get_accuracy(y_train, y_train_predictions)\n",
    "prec = precision_score(y_train, y_train_predictions, average=\"micro\")\n",
    "rec = recall_score(y_train, y_train_predictions, average=\"micro\")\n",
    "print(f\"precision is {prec}, recall is {rec}, accuracy = {acc}\")\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'nb_classifier.sav'\n",
    "pickle.dump(nb, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions from a saved model\n",
    "\n",
    "# load the model from disk\n",
    "filename = 'nb_classifier.sav'\n",
    "nb_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction_from_image():\n",
    "    \n",
    "    #load\n",
    "    input_img = matlab.acquire_kinect_image(img)\n",
    "    \n",
    "    # normalize\n",
    "    lego_img = np.zeros(input_img.shape)\n",
    "    lego_img = cv.normalize(input_img,  lego_img, 0, 255, cv.NORM_MINMAX)\n",
    "    \n",
    "#     # segment\n",
    "#     seg_img = imageproc.bg_segmentation(lego_img, show_img=True)\n",
    "    \n",
    "    # load class list\n",
    "    lego_img_cl = img_classes[i]\n",
    "    \n",
    "    # process image to datagrame\n",
    "    # takes a segmented image and draws contours\n",
    "    image_df, output_img = imageproc.process_image_to_df(lego_img, area_th = 100)\n",
    "    \n",
    "    # label dataframe from class list\n",
    "    image_df = imageproc.label_dataframe(image_df, class_list = lego_img_cl)\n",
    "\n",
    "    # get image name from original filename\n",
    "    image_name = lego_imgs[i].split('/')[2].split('.')[0]\n",
    "\n",
    "    # write output_image to disk with color codes\n",
    "    cv.imwrite(f\"images/classification_{i}_{image_name}.png\", output_img)\n",
    "    \n",
    "    # add the dataframe to the training dataframe\n",
    "    if i==0:\n",
    "        train_df = image_df\n",
    "    else:\n",
    "        train_df = pd.concat([train_df, image_df])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# result = loaded_model.get_predictions(X_test, Y_test)\n",
    "# print(result)\n",
    "\n",
    "# # use the test set to see how we do\n",
    "# y_test_predictions = nb.get_predictions(X_test)\n",
    "\n",
    "# # scores\n",
    "# acc = nb.get_accuracy(y_test, y_test_predictions)\n",
    "# prec = precision_score(y_test, y_test_predictions, average=\"micro\")\n",
    "# rec = recall_score(y_test, y_test_predictions, average=\"micro\")\n",
    "# print(f\"precision is {prec}, recall is {rec}, accuracy = {acc}\")\n",
    "\n",
    "# # confusion matrix\n",
    "# labels = [(i, c) for i, c in class_dict.items()]\n",
    "# cm = confusion_matrix(y_test, y_test_predictions)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# cax = ax.matshow(cm)\n",
    "# plt.title('confusion matrix of the classifier')\n",
    "# fig.colorbar(cax)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.show()\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootdir = 'images/train/'\n",
    "\n",
    "# for subdir, dirs, files in os.walk(rootdir):\n",
    "#     print(subdir, files)\n",
    "    \n",
    "    \n",
    "idx = 14\n",
    "lego_img = matlab.acquire_kinect_image(lego_imgs[idx])\n",
    "print(lego_imgs[idx])\n",
    "hsv_lower, hsv_upper = imageproc.hsv_slide_tool(lego_img)\n",
    "\n",
    "\n",
    "# normalizedImg = np.zeros(lego_img.shape)\n",
    "# normalizedImg = cv.normalize(lego_img,  normalizedImg, 0, 255, cv.NORM_MINMAX)\n",
    "# cv.imshow('dst_rt', normalizedImg)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib \n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "# joblib.dump(knn, 'filename.pkl') \n",
    "  \n",
    "# # Load the model from the file \n",
    "# knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# # Use the loaded model to make predictions \n",
    "# knn_from_joblib.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from glob import glob\n",
    "# f\n",
    "# # classes\n",
    "# classes = {0:\"background\",\n",
    "#           1:\"bright_yellow\",\n",
    "#           2: \"medium_blue\",\n",
    "#           3: \"darK_stone_gray\",\n",
    "#            4:\"white\",\n",
    "#            5:\"bright_red\",\n",
    "#            6:\"medium_lilac\",\n",
    "#            7:\"black\",\n",
    "#            8:\"bright_blue\",\n",
    "#            9:\"light_green\",\n",
    "#            10:\"bright_orange\",\n",
    "#            11:\"bright_green\"}\n",
    "\n",
    "# # dataset import\n",
    "# train_dir = 'images/train/'\n",
    "# train_dir_list = [(train_dir + v + '/') for k, v in classes.items()]\n",
    "\n",
    "# # test_list = [print(i, jpg) for i, (k, v) in enumerate(classes.items())]\n",
    "\n",
    "# for i, train_dir in enumerate(train_dir_list):\n",
    "#     result = list(Path(\".\").rglob(\"*.[pP][nN][gG]\"))\n",
    "#     for img in result:\n",
    "#         train_data.append((img, i))\n",
    "\n",
    "    \n",
    "# print(train_data)\n",
    "# # # Get the list of all the images\n",
    "# # Ektachrome_Images = Ektachrome_dir.glob('*.jpeg')\n",
    "# # HP5_Images = HP5_dir.glob('*.jpeg')\n",
    "# # Lomochrome_Purple_Images = Lomochrome_Purple_dir.glob('*.jpeg')\n",
    "# # Tri_X_Images = Tri_X_dir.glob('*.jpeg')\n",
    "# # Velvia_50_Images = Velvia_50_dir.glob('*.jpeg')\n",
    "\n",
    "# # # An empty list. We will insert the data into this list in (img_path, label) format\n",
    "# # train_data = []\n",
    "\n",
    "# # for img in Ektachrome_Images:\n",
    "# #     train_data.append((img,1))\n",
    "\n",
    "# # for img in HP5_Images:\n",
    "# #     train_data.append((img, 2))\n",
    "\n",
    "# # for img in Lomochrome_Purple_Images:\n",
    "# #     train_data.append((img, 3))\n",
    "\n",
    "# # for img in Tri_X_Images:\n",
    "# #     train_data.append((img, 4))\n",
    "\n",
    "# # for img in Velvia_50_Images:\n",
    "# #     train_data.append((img, 5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # test_image = matlab.acquire_kinect_image(\"images/legos_0.png\")\n",
    "\n",
    "# # # # use the segmentation function to segment the image.\n",
    "# # # seg_image = imageproc.bg_segmentation(test_image)\n",
    "\n",
    "# # # matlab.imshow(seg_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "\n",
    "# hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# # create an hsv mask\n",
    "# test_image = cv.inRange(hsv_image, \n",
    "#                          (50, 20, 0),\n",
    "#                          (160, 255, 255)).astype(np.uint8)\n",
    "\n",
    "# test_image = cv.bitwise_and(image, image, mask =test_image).astype(np.uint8)\n",
    "# print(test_image[0])\n",
    "\n",
    "# plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import the cherry images\n",
    "# # C:\\data\\BSYSE_530\\machine_vision\\images\\Cherries\n",
    "# # there are five, with different light conditions\n",
    "# # DSC_0052, 0054, 0056, 0057, 0058\n",
    "# # we need to take these images and cut them into little pieces for the process to work\n",
    "\n",
    "# # convert them to RGB\n",
    "# images = [cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0052.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0054.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0056.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0057.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0058.jpg\"), cv.COLOR_BGR2RGB)]\n",
    "\n",
    "# titles = [\"DSC_0052\", \"DSC_0054\", \"DSC_0056\",\"DSC_0057\",\"DSC_0058\"]\n",
    "\n",
    "# masked_images = []\n",
    "# masks = []\n",
    "# adj_images = []\n",
    "\n",
    "# # # # image adjustment, rescale intensity\n",
    "# # for i in range(0, 5):\n",
    "# #     img = images[i]\n",
    "# #     p2, p98 = np.percentile(img, (2, 98))\n",
    "# #     adj_img = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "# #     adj_images.append(adj_img)\n",
    "    \n",
    "# # create the mask\n",
    "# # try to screen out all the white regions\n",
    "# background_mask = cv.inRange(images[0],\n",
    "#                              (70,70,90),\n",
    "#                              (120,120,120)).astype(np.int) * -1\n",
    "# print(background_mask.shape)\n",
    "# print(type(background_mask))\n",
    "# # background_mask = morphology.binary_dilation(background_mask, np.ones((3, 3)))\n",
    "# # closing\n",
    "# background_mask = morphology.closing(background_mask, morphology.disk(2))\n",
    "\n",
    "# # print(background_mask.shape)\n",
    "# # print(background_mask)\n",
    "# # print(np.mean(images[0][650:700,400:500,0]), np.mean(images[0][600:700,0:100,1]), np.mean(images[0][600:700,0:100,2]))\n",
    "\n",
    "# # now use BGR2HSV to reverse the red and blue to make it easier for hsv filtering of the red (not around 0/360 break)\n",
    "# hsv_image = cv.cvtColor(images[0], cv.COLOR_BGR2HSV)\n",
    "\n",
    "# # create an hsv mask\n",
    "# cherry_mask = cv.inRange(hsv_image, \n",
    "#                          (70, 30, 20),\n",
    "#                          (255, 255, 255)).astype(np.int)\n",
    "\n",
    "\n",
    "# cherry_mask = get_tgi_mask(cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0056.jpg\"), cv.COLOR_BGR2RGB).astype(np.float64))\n",
    "\n",
    "# # make that array of truth values 0 or 255 into a 1 0 array\n",
    "# # cherry_mask = np.where(cherry_mask > 250, 1, 0).astype(np.int)\n",
    "\n",
    "# # median filter to denoise\n",
    "# # cherry_mask = ndimage.median_filter(cherry_mask, size=(3, 3)).astype(np.int)\n",
    "\n",
    "\n",
    "# # do a little dilation to make the mask look nice\n",
    "# cherry_mask = morphology.binary_dilation(cherry_mask, np.ones((3, 3)))\n",
    "\n",
    "# # closing\n",
    "# # cherry_mask = morphology.closing(cherry_mask, morphology.disk(4))\n",
    "\n",
    "# # erode the mask\n",
    "# cherry_mask = morphology.erosion(cherry_mask, morphology.disk(2))\n",
    "\n",
    "# #combine the cherry mask and the background mask\n",
    "# # cherry_mask = cherry_mask + background_mask\n",
    "\n",
    "# for image in images:\n",
    "\n",
    "#     # apply the mask\n",
    "#     masked_image = np.zeros(image.shape)\n",
    "#     for channel in range(image.shape[2]):\n",
    "#         masked_image[:,:,channel] = image[:,:,channel] * cherry_mask\n",
    "    \n",
    "#     # the images are going back into \"BGR\" but thats really RGB\n",
    "#     masked_images.append(masked_image.astype(np.uint8))\n",
    "\n",
    "# # # show the images from the last batch just for kicks\n",
    "# # plot_images(titles=[\"cherry_mask\"], \n",
    "# #             images=[cherry_mask],\n",
    "# #             fsize=30)\n",
    "\n",
    "\n",
    "\n",
    "# # # show the images from the last batch just for kicks\n",
    "# plot_images(titles=titles, \n",
    "#             images=masked_images,\n",
    "#             fsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['y'])\n",
    "\n",
    "# # produce the individual images we are going to use for our data set in the neural network step\n",
    "# for light_level, img_rgb in enumerate(masked_images):\n",
    "\n",
    "#     # create the image subsets and name them as appropriate for location\n",
    "#     cherry_0_0 = img_rgb[100:200,200:300,:]\n",
    "#     cherry_0_1 = img_rgb[80:180,300:400,:]\n",
    "#     cherry_0_2 = img_rgb[90:190,375:475,:]\n",
    "#     cherry_0_3 = img_rgb[100:200,500:600,:]\n",
    "#     cherry_0_4 = img_rgb[100:200,600:700,:]\n",
    "#     cherry_0_5 = img_rgb[100:200,700:800,:]\n",
    "\n",
    "#     cherry_1_0 = img_rgb[225:325,190:290,:]\n",
    "#     cherry_1_1 = img_rgb[225:325,275:375,:]\n",
    "#     cherry_1_2 = img_rgb[225:325,375:475,:]\n",
    "#     cherry_1_3 = img_rgb[225:325,500:600,:]\n",
    "#     cherry_1_4 = img_rgb[225:325,600:700,:]\n",
    "#     cherry_1_5 = img_rgb[225:325,700:800,:]\n",
    "\n",
    "#     cherry_2_0 = img_rgb[375:475,175:275,:]\n",
    "#     cherry_2_1 = img_rgb[375:475,275:375,:]\n",
    "#     cherry_2_2 = img_rgb[375:475,375:475,:]\n",
    "#     cherry_2_3 = img_rgb[375:475,500:600,:]\n",
    "#     cherry_2_4 = img_rgb[375:475,600:700,:]\n",
    "#     cherry_2_5 = img_rgb[375:475,700:800,:]\n",
    "    \n",
    "#     rectangle_0 = img_rgb[525:550,350:350 + 25,:]\n",
    "#     rectangle_1 = img_rgb[525:550,382:382 + 25,:]\n",
    "#     rectangle_2 = img_rgb[527:552,415:415 + 25,:]\n",
    "#     rectangle_3 = img_rgb[527:552,450:450 + 25,:]\n",
    "#     rectangle_4 = img_rgb[528:553,484:484 + 25,:]\n",
    "#     rectangle_5 = img_rgb[528:553,519:519 + 25,:]\n",
    "#     rectangle_6 = img_rgb[529:554,554:554 + 25,:]\n",
    "        \n",
    "#     sticky_note = img_rgb[250:430,800:1000,:]\n",
    "\n",
    "#     images = [cherry_0_0, cherry_0_1, cherry_0_2, cherry_0_3, cherry_0_4, cherry_0_5,\n",
    "#               cherry_1_0, cherry_1_1, cherry_1_2, cherry_1_3, cherry_1_4, cherry_1_5,\n",
    "#               cherry_2_0, cherry_2_1, cherry_2_2, cherry_2_3, cherry_2_4, cherry_2_5,\n",
    "#               rectangle_0, rectangle_1, rectangle_2, rectangle_3, rectangle_4, rectangle_5,\n",
    "#               rectangle_6, sticky_note]\n",
    "\n",
    "# #     labels = [\"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\",\n",
    "# #               \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\",\n",
    "# #               \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\",\n",
    "# #               \"light_color_rectangle\", \"light_color_rectangle\", \"moderate_color_rectangle\", \"moderate_color_rectangle\", \"moderate_color_rectangle\", \"dark_color_rectangle\",\n",
    "# #               \"dark_color_rectangle\", \"sticky_notes\"]\n",
    "\n",
    "#     labels = [0, 0, 0, 0, 0, 0,\n",
    "#               1, 1, 1, 1, 1, 1,\n",
    "#               2, 2, 2, 2, 2, 2,\n",
    "#               3, 3, 4, 4, 4, 5, 5, 6]\n",
    "    \n",
    "#     labels_dict = {0: \"light_color_cherries\",\n",
    "#                   1: \"moderate_color_cherries\",\n",
    "#                   2: \"dark_color_cherries\",\n",
    "#                   3: \"light_color_rectangles\",\n",
    "#                   4: \"moderate_color_rectangles\",\n",
    "#                   5: \"dark_color_rectangles\",\n",
    "#                   6: \"sticky_notes\"}\n",
    "    \n",
    "#     titles = [\"cherry_0_0\", \"cherry_0_1\", \"cherry_0_2\", \"cherry_0_3\", \"cherry_0_4\", \"cherry_0_5\",\n",
    "#               \"cherry_1_0\", \"cherry_1_1\", \"cherry_1_2\", \"cherry_1_3\", \"cherry_1_4\", \"cherry_1_5\",\n",
    "#               \"cherry_2_0\", \"cherry_2_1\", \"cherry_2_2\", \"cherry_2_3\", \"cherry_2_4\", \"cherry_2_5\",\n",
    "#               \"rectangle_0\", \"rectangle_1\", \"rectangle_2\", \"rectangle_3\", \"rectangle_4\", \"rectangle_5\",\n",
    "#               \"rectangle_6\", \"sticky_note\"]\n",
    "\n",
    "    \n",
    "#     # iterate through the zone of interest images\n",
    "#     for i, image in enumerate(images):\n",
    "                \n",
    "# #         # set file name with light level and image title                       \n",
    "# #         filename =  str(labels[i]) + \" \" + titles[i] + \"_\" + str(light_level) + \".jpg\"\n",
    "               \n",
    "# #         # resize all images to same size for later use\n",
    "# #         bgr_image = cv.resize(image, (100,100), interpolation = cv.INTER_AREA)\n",
    "# #         bgr_image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "# #         cv.imwrite(\"cherries/\" + filename, bgr_image)    \n",
    "\n",
    "# #         # do your dataset creation right here. \n",
    "# #         hsv_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2HSV)\n",
    "        \n",
    "#         # \n",
    "#         p1, p2 = np.percentile(image[:,:,0], (2, 99))\n",
    "#         red_channel = exposure.rescale_intensity(image[:,:,0], in_range=(p1, p2))\n",
    "#         blue_channel = exposure.rescale_intensity(image[:,:,1], in_range=(p1, p2))\n",
    "#         green_channel = exposure.rescale_intensity(image[:,:,2], in_range=(p1, p2))\n",
    "            \n",
    "#         test_image = image.astype(np.float64)\n",
    "#         r = test_image[:,:,0] / np.max(test_image[:,:,0])\n",
    "#         g = test_image[:,:,1] / np.max(test_image[:,:,1])\n",
    "#         b = test_image[:,:,2] / np.max(test_image[:,:,2])\n",
    "        \n",
    "#         #  gli, ngrdi, r_bg, rbg, tgi*, br, rg\n",
    "#         rg_index_labels = [\"gli\", \"ngrdi\", \"r_bg\", \"rbg\", \"tgi\", \"br\", \"rg\"]\n",
    "#         rg_index = [calc_index(test_image, idx) for idx in rg_index_labels]\n",
    "\n",
    "#         # get the binary mask for this image, convert to unsigned 8-bit int\n",
    "#         bin_image = get_tgi_mask(image)\n",
    "#         print(type(bin_image), bin_image.dtype)\n",
    "#         contours, hier = cv.findContours(bin_image, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "#         cnt = contours[0]\n",
    "#         x, y, w, h = cv.boundingRect(cnt)\n",
    "        \n",
    "#         area = np.sum(bin_image)\n",
    "#         cnt_area = cv.contourArea(cnt)\n",
    "#         aspect_ratio = float(w)/h\n",
    "#         rect_area = w * h\n",
    "#         extent = float(cnt_area)/rect_area\n",
    "#         hull = cv.convexHull(cnt)\n",
    "#         hull_area = cv.contourArea(hull)\n",
    "#         solidity = float(cnt_area)/hull_area\n",
    "#         eq_diameter = np.sqrt(4*cnt_area/np.pi)\n",
    "    \n",
    "    \n",
    "        \n",
    "#         # try converting the images to pandas data frames, each of these channels and indices as a reshaped column. \n",
    "#         # then use pandas data frame commands to get some values\n",
    "#         df_images = pd.DataFrame()\n",
    "#         df_images[\"r_rs\"] = np.ndarray.flatten(red_channel)\n",
    "#         df_images[\"b_rs\"] = np.ndarray.flatten(green_channel)\n",
    "#         df_images[\"g_rs\"] = np.ndarray.flatten(blue_channel)\n",
    "#         df_images[\"r\"] = np.ndarray.flatten(r)\n",
    "#         df_images[\"b\"] = np.ndarray.flatten(g)\n",
    "#         df_images[\"g\"] = np.ndarray.flatten(b)\n",
    "#         df_images[\"gli\"] = np.ndarray.flatten(rg_index[0])\n",
    "#         df_images[\"ngrdi\"] = np.ndarray.flatten(rg_index[1])\n",
    "#         df_images[\"r_bg\"] = np.ndarray.flatten(rg_index[2])\n",
    "#         df_images[\"rbg\"] = np.ndarray.flatten(rg_index[3])\n",
    "#         df_images[\"tgi\"] = np.ndarray.flatten(rg_index[4])\n",
    "#         df_images[\"br\"] = np.ndarray.flatten(rg_index[5])\n",
    "#         df_images[\"rg\"] = np.ndarray.flatten(rg_index[6])\n",
    "               \n",
    "#         df = df.append({'y' : labels[i],\n",
    "#                         'mean_r_rs': df_images.r_rs[df_images.r_rs > 0].mean(),\n",
    "#                         'mean_g_rs': df_images.g_rs[df_images.g_rs > 0].mean(),\n",
    "#                         'mean_b_rs': df_images.b_rs[df_images.b_rs > 0].mean(),\n",
    "#                         'area': area,\n",
    "#                         \"cnt_area\": cnt_area,\n",
    "# #                         \"aspect_ratio\": aspect_ratio,\n",
    "# #                         \"rect_area\": rect_area,\n",
    "# #                         \"extent\": extent,\n",
    "# #                         \"hull_area\": hull_area, \n",
    "# #                         \"solidity\": solidity,\n",
    "# #                         \"eq_diameter\": eq_diameter,\n",
    "#                         'mean_r': df_images.r[df_images.r > 0].mean(),\n",
    "#                         'mean_g': df_images.g[df_images.g > 0].mean(),\n",
    "#                         'mean_b': df_images.b[df_images.b > 0].mean(),\n",
    "#                         'gli': df_images.gli[df_images.gli < 0].mean(),\n",
    "# #                         'ngrdi': df_images.ngrdi[df_images.ngrdi < 0].mean(),\n",
    "#                         'r_bg': df_images.r_bg.mean(),\n",
    "#                         'rbg': df_images.rbg.mean(),\n",
    "#                         'tgi': df_images.tgi[df_images.tgi < 0].mean(),\n",
    "#                         'br': df_images.br[df_images.br < 0].mean(),\n",
    "#                         'rg': df_images.rg.mean()\n",
    "#                        }, ignore_index=True)\n",
    "        \n",
    "\n",
    "#         # show the images from the last batch just for kicks\n",
    "# plot_images(titles=rg_index_labels, \n",
    "#             images=rg_index,\n",
    "#             fsize=30)\n",
    "\n",
    "# for image in rg_index:\n",
    "#     flat_img = np.ndarray.flatten(image)\n",
    "#     print(flat_img.min(), flat_img.max())\n",
    "# print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do a wacky thing here\n",
    "# # wacky_images = [exposure.equalize_hist(img[:,:,0]) for img in images]\n",
    "# # wacky_images = [exposure.equalize_adapthist(img[:,:,0]) for img in images]\n",
    "\n",
    "# test_image = cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0052.jpg\"), cv.COLOR_BGR2RGB).astype(np.float64)\n",
    "# r = test_image[:,:,0] / np.max(test_image[:,:,0])\n",
    "# g = test_image[:,:,1] / np.max(test_image[:,:,1])\n",
    "# b = test_image[:,:,2] / np.max(test_image[:,:,2])\n",
    "\n",
    "\n",
    "# #  gli, ngrdi, r_bg, rbg, tgi*, br, rg\n",
    "# rg_index_labels = [\"gli\", \"ngrdi\", \"r_bg\", \"rbg\", \"tgi\", \"br\", \"rg\"]\n",
    "# rg_index = [calc_index(test_image, idx) for idx in rg_index_labels]\n",
    "\n",
    "# # show the images from the last batch just for kicks\n",
    "# plot_images(titles=rg_index_labels, \n",
    "#             images=rg_index,\n",
    "#             fsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
