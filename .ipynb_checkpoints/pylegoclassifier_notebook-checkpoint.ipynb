{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pylegoclassifier workbook\n",
    "### magnus wood, december 2020, bsyse 530 semester project\n",
    "The below code block will be used in the 'pylegoclassifer.py' module. It will be used in the matlab integration, where images obtained by Eric will use functions from this code to do lego color classification.\n",
    "\n",
    "This jupyter notebook exists solely for developing it. I should probably share it too.\n",
    "\n",
    "### pylegoclassifier.py functionality\n",
    "### The code needs to do this:\n",
    "\n",
    "1. Take an image file in and ensure it is in the right format.\n",
    "2. Perform background segmentation using ImageSegmentation.\n",
    "3. Data extraction:\n",
    "    a. \n",
    "    b. \n",
    "4. Pass the dataframe to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile pylegoclassifier.py\n",
    "\n",
    "# import the needed packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "import os\n",
    "from math import pi\n",
    "from math import isnan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(26)\n",
    "\n",
    "# the NaiveBayes classifier I wrote for assignment 6 in BSYSE_530, modified a little for this purpose\n",
    "class NaiveBayes:\n",
    "    # P(c|x) = P(x|c) * P(c) / P(x)\n",
    "    # P(x|x) is the posterior probability\n",
    "    # P(x|c) is the likelihood\n",
    "    # P(c) is the class prior probability, or the prob of c occuring indpendently. \n",
    "    # P(x) is the predictor prior probability, or the prob of x occuring independently\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        # define class variables\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        # calculate statistics for all those features\n",
    "        self.calc_statistics(features, target)\n",
    "        \n",
    "        # prior is the random chance of drawing a particular class based on its proportion in the dataset\n",
    "        self.prior = self.calc_prior(features, target)\n",
    "        \n",
    "              \n",
    "    def get_predictions(self, input_vector):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(len(input_vector)):\n",
    "            result = self.calc_posterior((input_vector.iloc[i,:]))\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "     \n",
    "\n",
    "    def predict(self, observation):\n",
    "        #call the calc_posterior function on the observation\n",
    "        pred_class = self.calc_posterior(observation)\n",
    "        return pred_class\n",
    "        \n",
    "        \n",
    "    def calc_statistics(self, features, target):\n",
    "        # calculate mean, variance for each column and convert to numpy array\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    \n",
    "    def calc_prior(self, features, target):\n",
    "        # this is the probability of picking one of a class at random from the dataset\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)/self.rows).to_numpy())\n",
    "        return self.prior\n",
    "    \n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        # this is the probability, post evidence\n",
    "        # x is a numpy array\n",
    "        # x is feature vector for one observation \n",
    "                \n",
    "        # make a list that we will add each classes posterior prob to\n",
    "        posteriors = []\n",
    "        \n",
    "        # iterate through the classes\n",
    "        for i in range(0, self.count):\n",
    "            # for each class look at the prior probability for the class\n",
    "            prior = self.prior[i]\n",
    "            \n",
    "            # calculate the conditional probability for the \n",
    "            conditional = np.sum(self.gaussian_density(i, x))\n",
    "            posterior = prior + conditional\n",
    "            #  print(f\"i = {i}, prior = {prior}, conditional = {conditional}, posterior = {posterior}\")\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "        \n",
    "        \n",
    "    def gaussian_density(self, class_idx, x):\n",
    "        # calc probability from gaussian denssityy fucntion (normal dist)\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        # this part sucked and I had a typo that cost me hours\n",
    "        numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "        \n",
    "    \n",
    "    def pdf(self, x, mean, stdev):\n",
    "        # calculate probability density function\n",
    "        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))\n",
    "        return exponent * (1/(np.sqrt(2*np.pi)*stdev))\n",
    "\n",
    "        \n",
    "    def get_accuracy(self, test, predictions):\n",
    "        correct = 0\n",
    "        for i in range(len(test)):\n",
    "            if test.iloc[i] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct / float(len(test)))\n",
    "\n",
    "\n",
    "# TODO: read these and see how it works        \n",
    "# https://www.mathworks.com/help/matlab/matlab_external/matlab-arrays-as-python-variables.html        \n",
    "# https://www.mathworks.com/help/matlab/matlab_external/passing-data-to-python.html        \n",
    "            \n",
    "# this exists only for my testing purposes\n",
    "class MatlabSurrogate():\n",
    "    def __init__(self):\n",
    "        self.state_of_mind = \"Badass.\"\n",
    "        \n",
    "        \n",
    "    def acquire_kinect_image(self, filename):\n",
    "        # give this function a filename, and it will load that image with opencv\n",
    "        # this will be a BGR format, because that is how opencv rolls\n",
    "        kinect_image = cv.imread(filename)\n",
    "        print(f\"kinect has acquired the image with shape = {kinect_image.shape}\")\n",
    "        return kinect_image\n",
    "    \n",
    "    \n",
    "    # function to display images resized, using opencv\n",
    "    def imshow(self, image):\n",
    "        w, h = int(image.shape[1]/4), int(image.shape[0]/4)\n",
    "        cv.namedWindow(\"output\", cv.WINDOW_NORMAL)\n",
    "        cv.resizeWindow(\"output\", (w, h))\n",
    "        cv.imshow(\"output\", image)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "# I should probably have one image processing class that takes in a single image and then spits out a dataframe that could be used for prediction\n",
    "# replaces ImageSegmenter\n",
    "class ImageProcess():\n",
    "    def __init__(self):\n",
    "        print(\"image processor activated! use 'process_image_to_df()' to get back a pandas df\")\n",
    "    \n",
    "    def dummy_method(self, a):\n",
    "        if type(a) is np.ndarray:\n",
    "            result = \"object is a numpy.ndarray, this is perfect. Is the image RGB order or BGR?\"\n",
    "            return result\n",
    "        else:\n",
    "            result = \"object is a \" + str(type(a)) + \"and I'm gonna have a hard time with that\"\n",
    "            return result\n",
    "      \n",
    "    \n",
    "        \n",
    "    def bg_segmentation(self, image, mode=\"hsv\"):\n",
    "        \n",
    "        if mode==\"sobel\":\n",
    "            from skimage.filters import sobel\n",
    "            \n",
    "            gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # find the edges\n",
    "            elev_map = sobel(gray_image)\n",
    "            \n",
    "            # threshold it\n",
    "            foreground = np.zeros_like(image)\n",
    "            foreground[gray_image < 30] = 1\n",
    "            foreground[gray_image > 150] = 2\n",
    "          \n",
    "            #TODO add this\n",
    "        \n",
    "        else:\n",
    "            \n",
    "#             # gaussian blur\n",
    "#             blur_image = ndimage.gaussian_filter(image, sigma=4)\n",
    "            \n",
    "            \n",
    "            # create an hsv mask for red colors\n",
    "            color_mask = cv.inRange(cv.cvtColor(image, cv.COLOR_BGR2HSV), \n",
    "                                 (0, 0, 100),\n",
    "                                 (180, 255, 255)).astype(np.uint8)\n",
    "            \n",
    "            black_mask = cv.inRange(cv.cvtColor(image, cv.COLOR_BGR2HSV), \n",
    "                                 (0, 0, 0),\n",
    "                                 (179, 255, 30)).astype(np.uint8)\n",
    "            \n",
    "#             hsv_mask = black_mask + color_mask\n",
    "            hsv_mask = black_mask + color_mask\n",
    "            \n",
    "            hsv_mask = np.where(hsv_mask > 0, 1, 0).astype(np.uint8)\n",
    "\n",
    "            \n",
    "#             # erode the mask\n",
    "#             hsv_mask = morphology.erosion(hsv_mask, morphology.disk(5))\n",
    "            \n",
    "#             # gaussian blur\n",
    "            hsv_mask = ndimage.gaussian_filter(hsv_mask, sigma=1)\n",
    "\n",
    "            # erode the mask\n",
    "            hsv_mask = morphology.erosion(hsv_mask, morphology.disk(5))\n",
    "\n",
    "            # median filter to despeckle\n",
    "            hsv_mask = ndimage.median_filter(hsv_mask, size=(3, 3)).astype(np.uint8)\n",
    "\n",
    "            # binary dilation \n",
    "            hsv_mask = morphology.binary_dilation(hsv_mask, np.ones((20, 20))).astype(np.uint8)\n",
    "\n",
    "            # fill the holes\n",
    "            hsv_mask = ndimage.binary_fill_holes(hsv_mask).astype(np.uint8)\n",
    "\n",
    "            # erode the mask\n",
    "            hsv_mask = morphology.erosion(hsv_mask, morphology.disk(5))\n",
    "            \n",
    "            # TODO: remove this it is for testing purposes to show the segmentation\n",
    "            m = MatlabSurrogate()\n",
    "            m.imshow(cv.bitwise_and(image, image, mask=hsv_mask).astype(np.uint8))\n",
    "            \n",
    "            # apply the mask and return the result        \n",
    "            return hsv_mask\n",
    "\n",
    "        \n",
    "    def bg_segmentation_eucdist(self, img_cube, roi_origin=(50, 50)):\n",
    "        \n",
    "        def euc_dist(roi_channels, sample_channels):\n",
    "            dist = [(roi_channels[i] - sample_channels[i])**2 for i in range(0, len(sample_channels))]\n",
    "            euc_dist = np.sqrt(np.sum(dist))\n",
    "            return euc_dist\n",
    "        \n",
    "        # variables\n",
    "        dist_th = 150\n",
    "\n",
    "        # define the roi using these values and use it to subset my_image and return the subset image\n",
    "        roi = np.array(img_cube[roi_origin[0]:roi_origin[0]+20, roi_origin[1]:roi_origin[1]+20,:])\n",
    "\n",
    "        ################################################################\n",
    "        # calculate the mean intensity value for the roi at each channel and store in a vector\n",
    "        roi_mean_vector = np.zeros(shape=(img_cube.shape[2], 1))\n",
    "\n",
    "        # iterate through all the channels\n",
    "        for channel in range(0, img_cube.shape[2]):\n",
    "            # channel of interest, reshaped to a vector\n",
    "            coi = img_cube[:,:,channel]\n",
    "            coi_vector = coi.reshape((img_cube.shape[0]* img_cube.shape[1]), 1)\n",
    "\n",
    "            # mean intensity for the channel added to intensity vector\n",
    "            roi_mean_vector[channel] = np.mean(coi_vector)\n",
    "        #################################################################\n",
    "        # knn\n",
    "        output_array = np.zeros(shape=(img_cube.shape[0], img_cube.shape[1]))\n",
    "\n",
    "        # time this process\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in range(0, output_array.shape[0]):\n",
    "            for j in range(0, output_array.shape[1]):\n",
    "                # calculate the euc distance from the pixel[i,j] to roi_mean_vector\n",
    "                distance = euc_dist(roi_mean_vector, img_cube[i, j])\n",
    "                if distance < dist_th:\n",
    "                    output_array[i, j] = 1\n",
    "\n",
    "        print(time.time() - start_time)\n",
    "\n",
    "        # TODO: image enhancement on the output array to get rid of holes\n",
    "\n",
    "        # label the objects\n",
    "        labels, num_features = ndimage.measurements.label(output_array)\n",
    "\n",
    "        # retain only the object 1, the apple\n",
    "        mask = np.where(labels == 1, 1, 0).reshape(output_array.shape)\n",
    "\n",
    "        # median filter to denoise\n",
    "        mask = ndimage.median_filter(mask, size=(3, 3)).astype(np.int)\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    # this is the parent function of this class, it will call the other classes\n",
    "    def process_image_to_df(self, image, area_th):\n",
    "        # get a mask by background segmentation using hsv values\n",
    "        mask = self.bg_segmentation(image)\n",
    "        \n",
    "        # output image with drawn on contours\n",
    "        output_image = image.copy()\n",
    "        \n",
    "        # find the contours of the detected objects in the image\n",
    "        contours, hier = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # create the df that we'll return for this image\n",
    "        df = pd.DataFrame(columns=['y'])\n",
    "\n",
    "      \n",
    "        # blank canvas\n",
    "        cimg = np.zeros_like(image)\n",
    "\n",
    "        # reset the object num\n",
    "        object_num = 0\n",
    "\n",
    "        # draw all the contours on the image\n",
    "        for cnt in contours:\n",
    "\n",
    "            # blank canvas\n",
    "            cimg_subset = np.zeros_like(image)\n",
    "\n",
    "            # get the x, y, w, h of the bounding rect for the contour\n",
    "            x, y, w, h = cv.boundingRect(cnt)\n",
    "\n",
    "            # contour features\n",
    "            area = cv.contourArea(cnt)\n",
    "            rect_area = w * h\n",
    "            fullosity = area / rect_area\n",
    "\n",
    "            # get rid of tiny objects that are probably noise\n",
    "            if area > area_th and fullosity > .5:\n",
    "                aspect_ratio = float(w)/h\n",
    "                extent = float(area/ rect_area)\n",
    "                hull = cv.convexHull(cnt)\n",
    "                hull_area = cv.contourArea(hull)\n",
    "                solidity = float(area)/hull_area\n",
    "\n",
    "\n",
    "                eq_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "                M= cv.moments(cnt)\n",
    "                cx= int(M['m10']/M['m00'])\n",
    "                cy= int(M['m01']/M['m00'])\n",
    "                    \n",
    "                # draw the contour on the blank image as a filled white object\n",
    "                cv.drawContours(cimg, [cnt], 0, color=(255, 255, 255), thickness=-1)\n",
    "\n",
    "                # draw the bounding box on the cimg and output img as a green boundary\n",
    "                cv.rectangle(cimg, (x, y), (x+w, y+h), (0, 255,0), 2)\n",
    "                cv.rectangle(output_image, (x, y), (x+w, y+h), (0, 255,0), 2)\n",
    "\n",
    "                # take this rectangle as a subset of the image, and calculate things within it\n",
    "                # define the object subset of the image and mask\n",
    "                cimg_subset = cimg[y:y+h, x:x+w]\n",
    "                img_subset = image[y:y+h, x:x+w, :]\n",
    "\n",
    "                img_subset_hsv = cv.cvtColor(img_subset, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                # create an hsv mask to remove the black background again\n",
    "                color_mask = cv.inRange(cv.cvtColor(img_subset, cv.COLOR_BGR2HSV), \n",
    "                                     (0, 0, 100),\n",
    "                                     (180, 255, 255)).astype(np.uint8)\n",
    "\n",
    "                black_mask = cv.inRange(cv.cvtColor(img_subset, cv.COLOR_BGR2HSV), \n",
    "                                     (0, 0, 0),\n",
    "                                     (90, 100, 10)).astype(np.uint8)\n",
    "\n",
    "                hsv_mask = black_mask + color_mask\n",
    "\n",
    "                # apply the mask\n",
    "                f = cv.bitwise_and(img_subset_hsv, img_subset_hsv, mask=hsv_mask).astype(np.uint8)\n",
    "\n",
    "                # calculate where the object is\n",
    "                pts = np.where(cimg_subset == 255)\n",
    "                hue = img_subset_hsv[pts[0], pts[1], 0]\n",
    "                sat = img_subset_hsv[pts[0], pts[1], 1]\n",
    "                val = img_subset_hsv[pts[0], pts[1], 2]\n",
    "                r = img_subset[pts[0], pts[1], 0]\n",
    "                g = img_subset[pts[0], pts[1], 1]\n",
    "                b = img_subset[pts[0], pts[1], 2]\n",
    "\n",
    "                # add the object labels to the cimg for identification\n",
    "                cv.putText(cimg, text= str(object_num), \n",
    "                           org=(cx - 5,cy - 5), \n",
    "                           fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "                           fontScale=3, \n",
    "                           color=(255,0,255), \n",
    "                           thickness=5, \n",
    "                           lineType=cv.LINE_AA)\n",
    "                \n",
    "                # add the object labels to the cimg for identification\n",
    "                cv.putText(output_image, text= str(object_num), \n",
    "                           org=(cx - 5,cy - 5), \n",
    "                           fontFace= cv.FONT_HERSHEY_SIMPLEX,\n",
    "                           fontScale=3, \n",
    "                           color=(255,255,255), \n",
    "                           thickness=5, \n",
    "                           lineType=cv.LINE_AA)\n",
    "                \n",
    "\n",
    "        #         print(r.mean(), g.mean(), b.mean(), gli.mean())\n",
    "                df = df.append({'color' : 0,\n",
    "                                'x': x,\n",
    "                                'y': y,\n",
    "                                'object_num': object_num,\n",
    "                                'r': r.mean(),\n",
    "                                'g': g.mean(),\n",
    "                                'b': b.mean(),\n",
    "                                'hue': hue.mean(),\n",
    "                                'sat': sat.mean(),\n",
    "                                'val': val.mean()\n",
    "                                 }, ignore_index=True)\n",
    "\n",
    "                # last thing we do on this loop is increment the object_num\n",
    "                object_num += 1\n",
    "    \n",
    "        # end result should be a pandas dataframe and the contour image with numbers\n",
    "        return df.sort_values(by='y', axis=0, ascending=True), output_image\n",
    "    \n",
    "    \n",
    "    def hsv_slide_tool(self, image):\n",
    "        \n",
    "        def empty(a):\n",
    "            pass\n",
    "        \n",
    "        h, w = int(image.shape[1]/4), int(image.shape[0]/4)\n",
    "        cv.namedWindow('masked_image', cv.WINDOW_NORMAL)\n",
    "        cv.resizeWindow('masked_image', 800, 600)\n",
    "        \n",
    "        cv.namedWindow(\"trackbars\")\n",
    "        cv.resizeWindow(\"trackbars\", 800, 300)\n",
    "        \n",
    "        cv.createTrackbar(\"hue_min\", \"trackbars\", 0, 179, empty)\n",
    "        cv.createTrackbar('hue_max', 'trackbars', 179, 179, empty)\n",
    "        cv.createTrackbar('sat_min', 'trackbars', 0, 255, empty)\n",
    "        cv.createTrackbar('sat_max', 'trackbars', 255, 255, empty)\n",
    "        cv.createTrackbar('val_min', 'trackbars', 0, 255, empty)\n",
    "        cv.createTrackbar('val_max', 'trackbars', 255, 255, empty)\n",
    "\n",
    "        while True:\n",
    "            # get image\n",
    "            img_hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "            \n",
    "            # get trackbar positions\n",
    "            h_min = cv.getTrackbarPos(\"hue_min\", \"trackbars\")\n",
    "            h_max = cv.getTrackbarPos('hue_max', 'trackbars')\n",
    "            s_min = cv.getTrackbarPos('sat_min', 'trackbars')\n",
    "            s_max = cv.getTrackbarPos('sat_max', 'trackbars')\n",
    "            v_min = cv.getTrackbarPos('val_min', 'trackbars')\n",
    "            v_max = cv.getTrackbarPos('val_max', 'trackbars')\n",
    "            \n",
    "            # create mask\n",
    "            lower_hsv = np.array([h_min, s_min, v_min])\n",
    "            higher_hsv = np.array([h_max, s_max, v_max])\n",
    "            mask = cv.inRange(img_hsv, lower_hsv, higher_hsv)\n",
    "            masked_image = cv.bitwise_and(img_hsv, img_hsv, mask=mask)\n",
    "            \n",
    "            \n",
    "            cv.imshow('masked_image', masked_image)\n",
    "            k = cv.waitKey(1000) & 0xFF # large wait time\n",
    "            if k == 113 or k == 27:\n",
    "                break\n",
    "        \n",
    "        cv.destroyAllWindows()\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image processor activated! use 'process_image_to_df()' to get back a pandas df\n",
      "kinect has acquired the image with shape = (2559, 1440, 3)\n"
     ]
    }
   ],
   "source": [
    "################### testing this out like its matlab ##################\n",
    "imageproc = ImageProcess() # does the background segmentation and other image processing methods, also data extraction\n",
    "matlab = MatlabSurrogate() # does some image loading and display, pretending we're using some \n",
    "\n",
    "test_image = matlab.acquire_kinect_image(\"images/legos_0.png\")\n",
    "\n",
    "# use the segmentation function to segment the image.\n",
    "# seg_image = imageproc.bg_segmentation(test_image)\n",
    "\n",
    "# matlab.imshow(seg_image)\n",
    "\n",
    "\n",
    "\n",
    "# # process the data fully and receive a df backfuschia\n",
    "image_df, cimg = imageproc.process_image_to_df(test_image, area_th = 1000)\n",
    "\n",
    "matlab.imshow(cimg)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect has acquired the image with shape = (2559, 1440, 3)\n"
     ]
    }
   ],
   "source": [
    "test_image = matlab.acquire_kinect_image(\"images/legos_0.png\")\n",
    "\n",
    "# use the segmentation function to segment the image.\n",
    "seg_image = imageproc.bg_segmentation(test_image)\n",
    "\n",
    "matlab.imshow(seg_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image processor activated! use 'process_image_to_df()' to get back a pandas df\n"
     ]
    }
   ],
   "source": [
    "hsv_image = cv.imread(\"images/legos_0.png\")\n",
    "imageproc = ImageProcess()\n",
    "imageproc.hsv_slide_tool(hsv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data and labels\n",
    "# X = df.iloc[:,1:]\n",
    "# y = df.iloc[:,0]\n",
    "\n",
    "# # split into train test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "# for c in np.unique(y).astype(np.int):\n",
    "#     print(c)\n",
    "#     X_c = X_train.iloc[:, c]\n",
    "#     print(X_c)\n",
    "\n",
    "# #         self._mean = X_c.groupby('')\n",
    "\n",
    "\n",
    "# P(A|B) = P(B|A) * P(A) / P(B)\n",
    "class NaiveBayes:\n",
    "    # P(c|x) = P(x|c) * P(c) / P(x)\n",
    "    # P(x|x) is the posterior probability\n",
    "    # P(x|c) is the likelihood\n",
    "    # P(c) is the class prior probability, or the prob of c occuring indpendently. \n",
    "    # P(x) is the predictor prior probability, or the prob of x occuring independently\n",
    "    \n",
    "    def fit(self, features, target):\n",
    "        # define class variables\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        # calculate statistics for all those features\n",
    "        self.calc_statistics(features, target)\n",
    "        \n",
    "        # prior is the random chance of drawing a particular class based on its proportion in the dataset\n",
    "        self.prior = self.calc_prior(features, target)\n",
    "#         print(f\"self.prior = {self.prior}\")\n",
    "#         print(f\"self.mean = {self.mean}\")\n",
    "#         print(f\"self.var = {self.var}\")\n",
    "        \n",
    "              \n",
    "    def get_predictions(self, input_vector):\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(len(input_vector)):\n",
    "#             print(f\"input_vector {i}\")\n",
    "            result = self.calc_posterior((input_vector.iloc[i,:]))\n",
    "#             print(f\"result is {result}\")\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "     \n",
    "\n",
    "    def predict(self, observation):\n",
    "        #call the calc_posterior function on the observation\n",
    "        pred_class = self.calc_posterior(observation)\n",
    "        return pred_class\n",
    "        \n",
    "        \n",
    "    def calc_statistics(self, features, target):\n",
    "        # calculate mean, variance for each column and convert to numpy array\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    \n",
    "    def calc_prior(self, features, target):\n",
    "        # this is the probability of picking one of a class at random from the dataset\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)/self.rows).to_numpy())\n",
    "        return self.prior\n",
    "    \n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        # this is the probability, post evidence\n",
    "        # x is a numpy array\n",
    "        # x is feature vector for one observation \n",
    "                \n",
    "        # make a list that we will add each classes posterior prob to\n",
    "        posteriors = []\n",
    "        \n",
    "        # iterate through the classes\n",
    "        for i in range(0, self.count):\n",
    "            # for each class look at the prior probability for the class\n",
    "            prior = self.prior[i]\n",
    "            \n",
    "            # calculate the conditional probability for the \n",
    "            conditional = np.sum(self.gaussian_density(i, x))\n",
    "            posterior = prior + conditional\n",
    "#             print(f\"i = {i}, prior = {prior}, conditional = {conditional}, posterior = {posterior}\")\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "        \n",
    "        \n",
    "    def gaussian_density(self, class_idx, x):\n",
    "        # calc probability from gaussian denssityy fucntion (normal dist)\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        # this part sucked and I had a typo that cost me hours\n",
    "        numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "        \n",
    "    \n",
    "    def pdf(self, x, mean, stdev):\n",
    "        # calculate probability density function\n",
    "        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))\n",
    "        return exponent * (1/(np.sqrt(2*np.pi)*stdev))\n",
    "\n",
    "        \n",
    "    def get_ accuracy(self, test, predictions):\n",
    "        correct = 0\n",
    "        for i in range(len(test)):\n",
    "            if test.iloc[i] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct / float(len(test)))\n",
    "                \n",
    "\n",
    "    def train_model\n",
    "# data and labels\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "# initialize the Naive Bayes class as an object\n",
    "nb = NaiveBayes()\n",
    "\n",
    "# sumnmarize the dataset to train the model\n",
    "# this gets class means, var, priors, etc\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# # # make predictions using the train set\n",
    "y_train_predictions = nb.get_predictions(X_train)\n",
    "acc = nb.get_accuracy(y_train, y_train_predictions)\n",
    "prec = precision_score(y_train, y_train_predictions, average=\"micro\")\n",
    "rec = recall_score(y_train, y_train_predictions, average=\"micro\")\n",
    "print(f\"precision is {prec}, recall is {rec}, accuracy = {acc}\")\n",
    "\n",
    "# confusion matrix\n",
    "labels = [(i, c) for i, c in labels_dict.items()]\n",
    "cm = confusion_matrix(y_train, y_train_predictions)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the test set to see how we do\n",
    "y_test_predictions = nb.get_predictions(X_test)\n",
    "\n",
    "# scores\n",
    "acc = nb.get_accuracy(y_test, y_test_predictions)\n",
    "prec = precision_score(y_test, y_test_predictions, average=\"micro\")\n",
    "rec = recall_score(y_test, y_test_predictions, average=\"micro\")\n",
    "print(f\"precision is {prec}, recall is {rec}, accuracy = {acc}\")\n",
    "\n",
    "# confusion matrix\n",
    "labels = [(i, c) for i, c in labels_dict.items()]\n",
    "cm = confusion_matrix(y_test, y_test_predictions)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib \n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "# joblib.dump(knn, 'filename.pkl') \n",
    "  \n",
    "# # Load the model from the file \n",
    "# knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# # Use the loaded model to make predictions \n",
    "# knn_from_joblib.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# create an hsv mask\n",
    "test_image = cv.inRange(hsv_image, \n",
    "                         (50, 20, 0),\n",
    "                         (160, 255, 255)).astype(np.uint8)\n",
    "\n",
    "test_image = cv.bitwise_and(image, image, mask =test_image).astype(np.uint8)\n",
    "print(test_image[0])\n",
    "\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # import the cherry images\n",
    "# # C:\\data\\BSYSE_530\\machine_vision\\images\\Cherries\n",
    "# # there are five, with different light conditions\n",
    "# # DSC_0052, 0054, 0056, 0057, 0058\n",
    "# # we need to take these images and cut them into little pieces for the process to work\n",
    "\n",
    "# # convert them to RGB\n",
    "# images = [cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0052.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0054.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0056.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0057.jpg\"), cv.COLOR_BGR2RGB),\n",
    "#           cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0058.jpg\"), cv.COLOR_BGR2RGB)]\n",
    "\n",
    "# titles = [\"DSC_0052\", \"DSC_0054\", \"DSC_0056\",\"DSC_0057\",\"DSC_0058\"]\n",
    "\n",
    "# masked_images = []\n",
    "# masks = []\n",
    "# adj_images = []\n",
    "\n",
    "# # # # image adjustment, rescale intensity\n",
    "# # for i in range(0, 5):\n",
    "# #     img = images[i]\n",
    "# #     p2, p98 = np.percentile(img, (2, 98))\n",
    "# #     adj_img = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "# #     adj_images.append(adj_img)\n",
    "    \n",
    "# # create the mask\n",
    "# # try to screen out all the white regions\n",
    "# background_mask = cv.inRange(images[0],\n",
    "#                              (70,70,90),\n",
    "#                              (120,120,120)).astype(np.int) * -1\n",
    "# print(background_mask.shape)\n",
    "# print(type(background_mask))\n",
    "# # background_mask = morphology.binary_dilation(background_mask, np.ones((3, 3)))\n",
    "# # closing\n",
    "# background_mask = morphology.closing(background_mask, morphology.disk(2))\n",
    "\n",
    "# # print(background_mask.shape)\n",
    "# # print(background_mask)\n",
    "# # print(np.mean(images[0][650:700,400:500,0]), np.mean(images[0][600:700,0:100,1]), np.mean(images[0][600:700,0:100,2]))\n",
    "\n",
    "# # now use BGR2HSV to reverse the red and blue to make it easier for hsv filtering of the red (not around 0/360 break)\n",
    "# hsv_image = cv.cvtColor(images[0], cv.COLOR_BGR2HSV)\n",
    "\n",
    "# # create an hsv mask\n",
    "# cherry_mask = cv.inRange(hsv_image, \n",
    "#                          (70, 30, 20),\n",
    "#                          (255, 255, 255)).astype(np.int)\n",
    "\n",
    "\n",
    "# cherry_mask = get_tgi_mask(cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0056.jpg\"), cv.COLOR_BGR2RGB).astype(np.float64))\n",
    "\n",
    "# # make that array of truth values 0 or 255 into a 1 0 array\n",
    "# # cherry_mask = np.where(cherry_mask > 250, 1, 0).astype(np.int)\n",
    "\n",
    "# # median filter to denoise\n",
    "# # cherry_mask = ndimage.median_filter(cherry_mask, size=(3, 3)).astype(np.int)\n",
    "\n",
    "\n",
    "# # do a little dilation to make the mask look nice\n",
    "# cherry_mask = morphology.binary_dilation(cherry_mask, np.ones((3, 3)))\n",
    "\n",
    "# # closing\n",
    "# # cherry_mask = morphology.closing(cherry_mask, morphology.disk(4))\n",
    "\n",
    "# # erode the mask\n",
    "# cherry_mask = morphology.erosion(cherry_mask, morphology.disk(2))\n",
    "\n",
    "# #combine the cherry mask and the background mask\n",
    "# # cherry_mask = cherry_mask + background_mask\n",
    "\n",
    "# for image in images:\n",
    "\n",
    "#     # apply the mask\n",
    "#     masked_image = np.zeros(image.shape)\n",
    "#     for channel in range(image.shape[2]):\n",
    "#         masked_image[:,:,channel] = image[:,:,channel] * cherry_mask\n",
    "    \n",
    "#     # the images are going back into \"BGR\" but thats really RGB\n",
    "#     masked_images.append(masked_image.astype(np.uint8))\n",
    "\n",
    "# # # show the images from the last batch just for kicks\n",
    "# # plot_images(titles=[\"cherry_mask\"], \n",
    "# #             images=[cherry_mask],\n",
    "# #             fsize=30)\n",
    "\n",
    "\n",
    "\n",
    "# # # show the images from the last batch just for kicks\n",
    "# plot_images(titles=titles, \n",
    "#             images=masked_images,\n",
    "#             fsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['y'])\n",
    "\n",
    "# # produce the individual images we are going to use for our data set in the neural network step\n",
    "# for light_level, img_rgb in enumerate(masked_images):\n",
    "\n",
    "#     # create the image subsets and name them as appropriate for location\n",
    "#     cherry_0_0 = img_rgb[100:200,200:300,:]\n",
    "#     cherry_0_1 = img_rgb[80:180,300:400,:]\n",
    "#     cherry_0_2 = img_rgb[90:190,375:475,:]\n",
    "#     cherry_0_3 = img_rgb[100:200,500:600,:]\n",
    "#     cherry_0_4 = img_rgb[100:200,600:700,:]\n",
    "#     cherry_0_5 = img_rgb[100:200,700:800,:]\n",
    "\n",
    "#     cherry_1_0 = img_rgb[225:325,190:290,:]\n",
    "#     cherry_1_1 = img_rgb[225:325,275:375,:]\n",
    "#     cherry_1_2 = img_rgb[225:325,375:475,:]\n",
    "#     cherry_1_3 = img_rgb[225:325,500:600,:]\n",
    "#     cherry_1_4 = img_rgb[225:325,600:700,:]\n",
    "#     cherry_1_5 = img_rgb[225:325,700:800,:]\n",
    "\n",
    "#     cherry_2_0 = img_rgb[375:475,175:275,:]\n",
    "#     cherry_2_1 = img_rgb[375:475,275:375,:]\n",
    "#     cherry_2_2 = img_rgb[375:475,375:475,:]\n",
    "#     cherry_2_3 = img_rgb[375:475,500:600,:]\n",
    "#     cherry_2_4 = img_rgb[375:475,600:700,:]\n",
    "#     cherry_2_5 = img_rgb[375:475,700:800,:]\n",
    "    \n",
    "#     rectangle_0 = img_rgb[525:550,350:350 + 25,:]\n",
    "#     rectangle_1 = img_rgb[525:550,382:382 + 25,:]\n",
    "#     rectangle_2 = img_rgb[527:552,415:415 + 25,:]\n",
    "#     rectangle_3 = img_rgb[527:552,450:450 + 25,:]\n",
    "#     rectangle_4 = img_rgb[528:553,484:484 + 25,:]\n",
    "#     rectangle_5 = img_rgb[528:553,519:519 + 25,:]\n",
    "#     rectangle_6 = img_rgb[529:554,554:554 + 25,:]\n",
    "        \n",
    "#     sticky_note = img_rgb[250:430,800:1000,:]\n",
    "\n",
    "#     images = [cherry_0_0, cherry_0_1, cherry_0_2, cherry_0_3, cherry_0_4, cherry_0_5,\n",
    "#               cherry_1_0, cherry_1_1, cherry_1_2, cherry_1_3, cherry_1_4, cherry_1_5,\n",
    "#               cherry_2_0, cherry_2_1, cherry_2_2, cherry_2_3, cherry_2_4, cherry_2_5,\n",
    "#               rectangle_0, rectangle_1, rectangle_2, rectangle_3, rectangle_4, rectangle_5,\n",
    "#               rectangle_6, sticky_note]\n",
    "\n",
    "# #     labels = [\"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\", \"light_color_cherry\",\n",
    "# #               \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\", \"moderate_color_cherry\",\n",
    "# #               \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\", \"dark_color_cherry\",\n",
    "# #               \"light_color_rectangle\", \"light_color_rectangle\", \"moderate_color_rectangle\", \"moderate_color_rectangle\", \"moderate_color_rectangle\", \"dark_color_rectangle\",\n",
    "# #               \"dark_color_rectangle\", \"sticky_notes\"]\n",
    "\n",
    "#     labels = [0, 0, 0, 0, 0, 0,\n",
    "#               1, 1, 1, 1, 1, 1,\n",
    "#               2, 2, 2, 2, 2, 2,\n",
    "#               3, 3, 4, 4, 4, 5, 5, 6]\n",
    "    \n",
    "#     labels_dict = {0: \"light_color_cherries\",\n",
    "#                   1: \"moderate_color_cherries\",\n",
    "#                   2: \"dark_color_cherries\",\n",
    "#                   3: \"light_color_rectangles\",\n",
    "#                   4: \"moderate_color_rectangles\",\n",
    "#                   5: \"dark_color_rectangles\",\n",
    "#                   6: \"sticky_notes\"}\n",
    "    \n",
    "#     titles = [\"cherry_0_0\", \"cherry_0_1\", \"cherry_0_2\", \"cherry_0_3\", \"cherry_0_4\", \"cherry_0_5\",\n",
    "#               \"cherry_1_0\", \"cherry_1_1\", \"cherry_1_2\", \"cherry_1_3\", \"cherry_1_4\", \"cherry_1_5\",\n",
    "#               \"cherry_2_0\", \"cherry_2_1\", \"cherry_2_2\", \"cherry_2_3\", \"cherry_2_4\", \"cherry_2_5\",\n",
    "#               \"rectangle_0\", \"rectangle_1\", \"rectangle_2\", \"rectangle_3\", \"rectangle_4\", \"rectangle_5\",\n",
    "#               \"rectangle_6\", \"sticky_note\"]\n",
    "\n",
    "    \n",
    "#     # iterate through the zone of interest images\n",
    "#     for i, image in enumerate(images):\n",
    "                \n",
    "# #         # set file name with light level and image title                       \n",
    "# #         filename =  str(labels[i]) + \" \" + titles[i] + \"_\" + str(light_level) + \".jpg\"\n",
    "               \n",
    "# #         # resize all images to same size for later use\n",
    "# #         bgr_image = cv.resize(image, (100,100), interpolation = cv.INTER_AREA)\n",
    "# #         bgr_image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "# #         cv.imwrite(\"cherries/\" + filename, bgr_image)    \n",
    "\n",
    "# #         # do your dataset creation right here. \n",
    "# #         hsv_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2HSV)\n",
    "        \n",
    "#         # \n",
    "#         p1, p2 = np.percentile(image[:,:,0], (2, 99))\n",
    "#         red_channel = exposure.rescale_intensity(image[:,:,0], in_range=(p1, p2))\n",
    "#         blue_channel = exposure.rescale_intensity(image[:,:,1], in_range=(p1, p2))\n",
    "#         green_channel = exposure.rescale_intensity(image[:,:,2], in_range=(p1, p2))\n",
    "            \n",
    "#         test_image = image.astype(np.float64)\n",
    "#         r = test_image[:,:,0] / np.max(test_image[:,:,0])\n",
    "#         g = test_image[:,:,1] / np.max(test_image[:,:,1])\n",
    "#         b = test_image[:,:,2] / np.max(test_image[:,:,2])\n",
    "        \n",
    "#         #  gli, ngrdi, r_bg, rbg, tgi*, br, rg\n",
    "#         rg_index_labels = [\"gli\", \"ngrdi\", \"r_bg\", \"rbg\", \"tgi\", \"br\", \"rg\"]\n",
    "#         rg_index = [calc_index(test_image, idx) for idx in rg_index_labels]\n",
    "\n",
    "#         # get the binary mask for this image, convert to unsigned 8-bit int\n",
    "#         bin_image = get_tgi_mask(image)\n",
    "#         print(type(bin_image), bin_image.dtype)\n",
    "#         contours, hier = cv.findContours(bin_image, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "#         cnt = contours[0]\n",
    "#         x, y, w, h = cv.boundingRect(cnt)\n",
    "        \n",
    "#         area = np.sum(bin_image)\n",
    "#         cnt_area = cv.contourArea(cnt)\n",
    "#         aspect_ratio = float(w)/h\n",
    "#         rect_area = w * h\n",
    "#         extent = float(cnt_area)/rect_area\n",
    "#         hull = cv.convexHull(cnt)\n",
    "#         hull_area = cv.contourArea(hull)\n",
    "#         solidity = float(cnt_area)/hull_area\n",
    "#         eq_diameter = np.sqrt(4*cnt_area/np.pi)\n",
    "    \n",
    "    \n",
    "        \n",
    "#         # try converting the images to pandas data frames, each of these channels and indices as a reshaped column. \n",
    "#         # then use pandas data frame commands to get some values\n",
    "#         df_images = pd.DataFrame()\n",
    "#         df_images[\"r_rs\"] = np.ndarray.flatten(red_channel)\n",
    "#         df_images[\"b_rs\"] = np.ndarray.flatten(green_channel)\n",
    "#         df_images[\"g_rs\"] = np.ndarray.flatten(blue_channel)\n",
    "#         df_images[\"r\"] = np.ndarray.flatten(r)\n",
    "#         df_images[\"b\"] = np.ndarray.flatten(g)\n",
    "#         df_images[\"g\"] = np.ndarray.flatten(b)\n",
    "#         df_images[\"gli\"] = np.ndarray.flatten(rg_index[0])\n",
    "#         df_images[\"ngrdi\"] = np.ndarray.flatten(rg_index[1])\n",
    "#         df_images[\"r_bg\"] = np.ndarray.flatten(rg_index[2])\n",
    "#         df_images[\"rbg\"] = np.ndarray.flatten(rg_index[3])\n",
    "#         df_images[\"tgi\"] = np.ndarray.flatten(rg_index[4])\n",
    "#         df_images[\"br\"] = np.ndarray.flatten(rg_index[5])\n",
    "#         df_images[\"rg\"] = np.ndarray.flatten(rg_index[6])\n",
    "               \n",
    "#         df = df.append({'y' : labels[i],\n",
    "#                         'mean_r_rs': df_images.r_rs[df_images.r_rs > 0].mean(),\n",
    "#                         'mean_g_rs': df_images.g_rs[df_images.g_rs > 0].mean(),\n",
    "#                         'mean_b_rs': df_images.b_rs[df_images.b_rs > 0].mean(),\n",
    "#                         'area': area,\n",
    "#                         \"cnt_area\": cnt_area,\n",
    "# #                         \"aspect_ratio\": aspect_ratio,\n",
    "# #                         \"rect_area\": rect_area,\n",
    "# #                         \"extent\": extent,\n",
    "# #                         \"hull_area\": hull_area, \n",
    "# #                         \"solidity\": solidity,\n",
    "# #                         \"eq_diameter\": eq_diameter,\n",
    "#                         'mean_r': df_images.r[df_images.r > 0].mean(),\n",
    "#                         'mean_g': df_images.g[df_images.g > 0].mean(),\n",
    "#                         'mean_b': df_images.b[df_images.b > 0].mean(),\n",
    "#                         'gli': df_images.gli[df_images.gli < 0].mean(),\n",
    "# #                         'ngrdi': df_images.ngrdi[df_images.ngrdi < 0].mean(),\n",
    "#                         'r_bg': df_images.r_bg.mean(),\n",
    "#                         'rbg': df_images.rbg.mean(),\n",
    "#                         'tgi': df_images.tgi[df_images.tgi < 0].mean(),\n",
    "#                         'br': df_images.br[df_images.br < 0].mean(),\n",
    "#                         'rg': df_images.rg.mean()\n",
    "#                        }, ignore_index=True)\n",
    "        \n",
    "\n",
    "#         # show the images from the last batch just for kicks\n",
    "# plot_images(titles=rg_index_labels, \n",
    "#             images=rg_index,\n",
    "#             fsize=30)\n",
    "\n",
    "# for image in rg_index:\n",
    "#     flat_img = np.ndarray.flatten(image)\n",
    "#     print(flat_img.min(), flat_img.max())\n",
    "# print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do a wacky thing here\n",
    "# # wacky_images = [exposure.equalize_hist(img[:,:,0]) for img in images]\n",
    "# # wacky_images = [exposure.equalize_adapthist(img[:,:,0]) for img in images]\n",
    "\n",
    "# test_image = cv.cvtColor(cv.imread(\"C:/data/BSYSE_530/machine_vision/images/Cherries/DSC_0052.jpg\"), cv.COLOR_BGR2RGB).astype(np.float64)\n",
    "# r = test_image[:,:,0] / np.max(test_image[:,:,0])\n",
    "# g = test_image[:,:,1] / np.max(test_image[:,:,1])\n",
    "# b = test_image[:,:,2] / np.max(test_image[:,:,2])\n",
    "\n",
    "\n",
    "# #  gli, ngrdi, r_bg, rbg, tgi*, br, rg\n",
    "# rg_index_labels = [\"gli\", \"ngrdi\", \"r_bg\", \"rbg\", \"tgi\", \"br\", \"rg\"]\n",
    "# rg_index = [calc_index(test_image, idx) for idx in rg_index_labels]\n",
    "\n",
    "# # show the images from the last batch just for kicks\n",
    "# plot_images(titles=rg_index_labels, \n",
    "#             images=rg_index,\n",
    "#             fsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
